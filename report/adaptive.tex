The process of adaptively making decision with uncertain outcomes is fundamental to many problems with partial observability. In such situations decision maker needs to make a sequence of decisions taking by accounting for past observations and adapting accordingly. It has been shown by Golovin and Krause \cite{Golovin} that if a problem is adaptively submodular, then an adaptive greedy algorithm is guaranteed to obtain near optimal solutions.
For the notion of clarity in the discussion of Application domains, we introduce the notion of adaptive submodularity and adaptive monotonicity in this section.

\subsubsection{Preliminaries and Notation II}
Let $V$ be the ground set. Assuming each item of the set $x\in V$ can take a number of states from a set of possible states $O$, we represent item states as $\phi:V \rightarrow O$ which is a function that gives the realization of the states of all items in the ground set. Hence $\phi(x)$ is the state of $x$ under the realization $\phi$. Now consider a random realization characterized by the random variable $\Phi$. Then we can assume a prior probability distribution over realizations as $p(\phi) := \mathbb{P}[\Phi = \phi]$. 
In cases where we observe only one realization $\Phi(x)$ at a time, as we pick an item $x \in V$ at a time; we can represent our observations so far with a partial realization $\chi$, i.e a function of a subset of $V$ and its observed states. Hence $\chi \subseteq V \times O$ is $\{(x,o):\chi(x) = o\}$. Here we denote the domain of $\chi$, i.e the set of items observed in $\chi$ as $dom(\chi) = \{ x: \exists o.(x,o) \in \chi \}$. When a partial realization $\chi$ is equal everywhere with $\phi$ in the $dom(\chi)$, they are {\it consistent} $\phi \sim \chi$.
This implies that all the items observed with specific states in $\chi$ have also been observed with the same states in $\phi$. Now we extend this notion to subsets by saying if $\chi$ and $\chi'$ are consistent with $\phi$ and $dom(\chi)\subseteq dom(\chi')$, then $\chi$ is a subrealization of $\chi'$. In a Partially Observable Markov Decision Problem (POMDP), sense partial realization are our belief states. They determine our posterior belief given the effect of all our actions and observations.
\[
 p(\phi\mid\chi) := \mathbb{P}[\Phi=\phi | \Phi \sim \chi]
\]

{\bf Definition 3: (Conditional Expected Marginal Benefit):} 
{\it Given a partial realization $\chi$ and a item $x$, the conditional expected marginal belief of $x$ conditioned on having already observed $\chi$ is denoted by $\delta(x\mid\chi)$
\[
 \delta(x\mid\chi) = \mathbb{E}[f(dom(\chi)\cup\{x\},\Phi) - f(dom(\chi),\Phi) \text{ } \mid \text{ } \Phi \sim \chi]
\]
}
{\bf Definition 4: (Adaptive Monotonicity):}
{\it A function $f:2^V \times O^V \rightarrow \Re_+$ is adaptive monotone with respect to the distribution $p(\phi)$ if the conditional expected marginal benefit of any item $x$ is non-negative, i.e $\forall \chi$ with $\mathbb{P}[\Phi \sim \chi] \geq 0$ and all $x\in V$ }
\[
 \delta(x\mid\chi) \geq 0
\]

{\bf Definition 4: (Adaptive Submodularity):}
{\it A function $f:2^V \times O^V \rightarrow \Re_+$ is adaptive submodular with respect to the distribution $p(\phi)$ if the conditional expected marginal benefit of any fixed item does not increase as more items are selected and their states are observed, i.e if $f$ is adaptively submodular w.r.t to $p(\phi)$ if $\forall \text{ } \chi$ and $\chi'$ where $\chi$ is a subrealization of $\chi'$ and all $x\in V \setminus dom(\chi')$ , the following condition holds true:}
\[
 \delta(x\mid\chi) \geq \delta(x\mid\chi')
\]
Given these definitions we can now use the greedy algorithm defined in Algorithm \ref{alg:greedy_adap} to give an $\alpha$ approximation to the best greedy solution for online maximization problems of adaptively montone submodular functions. This means we find an $x'$ such that
\[
 \delta(x'\mid\chi) \geq \frac{1}{\alpha}\delta(x\mid\chi)
\]

The budget for these maximization problems OR the number of rounds we'd like to maximize is similar to the cardinality constraint of submodular problems.

\begin{algorithm}[htb]
\caption{$\alpha$-Approximate Greedy Adaptive Algorithm}
\label{alg:greedy_adap}
\begin{algorithmic}[1]
\footnotesize
\State {\bf Input}: Budget $n$, ground set $V$, $p(\phi)$ and function $f$ 
\State {\bf Output}: $X \subset V$ where $\|X\| = n$
\State {\bf Initialize:} $X \leftarrow \emptyset$ and $\chi \leftarrow \emptyset$
\For{ i = 1 to n }
  \State $\forall x \in V\setminus X \text{; Evaluate } \delta(x\mid\chi) = \mathbb{E}[f(dom(\chi)\cup\{x\},\Phi) - f(dom(\chi),\Phi) \text{ } \mid \text{ } \Phi \sim \chi]$
  \State $x^* = \underset{x}{\operatorname{argmax }}\text{ } \delta(x\mid\chi)$
  \State $X \leftarrow X \cup {x^*}$
  \State $\text{Observe :} \Phi(x^*) \text{; Update: } \chi \leftarrow \chi \cup {x^*,\Phi(x^*)}$
\EndFor
\end{algorithmic}
\end{algorithm}